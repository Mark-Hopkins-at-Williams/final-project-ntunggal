{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Long Short-Term Memory (LSTMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class, we learned about recurrent neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RNN](./img/recurrent_neural_network.jpg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent neural networks are great because they have some sort of memory of the past, meaning they can handle sequential data. Not only can the input be read in sequentially, but output can also be generated sequentially through, for example, an encoder-decoder model RNN. Moreover, by applying a a fixed function at each step, there is no limit to the length of an input sequence to an RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, RNNs struggle in long sequences when the information needed comes from a long time ago in the sequence (long-term dependency). This is because error is backpropagated, and over many time steps (as in a long sequence), gradients can either explode or vanish. This prevents the model from learning correctly, if at all. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long short-term memory (LSTM) units aim to solve the problem of exploding/vanishing gradients by choosing parts of each input to \"remember\" at each step. By controlling what information and how much of it to store, LSTMs can learn long-term dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Long Short-Term Memory\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An LSTM unit has multiple parts. The most important part of an LSTM network is the cell state, which is a pathway that runs through the entire sequence. LSTMs can selectively add or remove information from the cell state through multiple gates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cell_state](./img/lstm_cell.png) \n",
    "![operations_key](./img/lstm_operations.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three main gates: the forget gate, the input gate, and the output gate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forget Gate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that happens in an LSTM unit is the forget gate decides how much information to keep in the cell state. In the below diagram:\n",
    "- $x_t$ represents the next token in the sequence\n",
    "- $h_{t-1}$ represents the output from the last LSTM unit\n",
    "- $\\sigma$ is the sigmoid activation function.\n",
    "- The output $f_t$ is a value between 0 and 1, with 0 representing \"get rid of all information\" and 1 representing \"keep all information.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![forget_gate](./img/lstm_forget.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h_{t-1}$ and $x_t$ are concatenated and multiplied by weight $W_f$. Then a bias $b_f$ is added. Finally, a sigmoid function is applied, resulting in an $f_t$ between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the unit decides how much new information we will store in the cell state. The layer that decides this is called the input gate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Gate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![input_gate](./img/lstm_input.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input gate has two parts:\n",
    "- $i_t$ decides which values in the cell state will be updated\n",
    "- $\\tilde{C_t}$ is a vector \"candidate values\" to be added to the cell state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, $i_t$ is calculated by multiplying $h_{t-1}$ concatenated with $x_t$ by weight $W_i$. A bias $b_i$ is then added, and the sigmoid is applied to the sum. We then calculate $\\tilde{C_t}$ by concatenating $h_{t-1}$ with $x_t$, multiplying the sum by weight $W_C$, then adding a bias $b_C$. Finally, $i_t$ and $\\tilde{C_t}$ are multiplied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After $f_t$, $i_t$ and $\\tilde{C_t}$ are calculated, the cell state is updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![update_cell_state](./img/lstm_update_cell_state.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Gate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last part of the LSTM unit is the output gate, which decides what the LSTM unit outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![output_gate](./img/lstm_output.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the formulas above, we first calculate $o_t$. A concatenated $h_{t-1}$ and $x_t$ is multiplied by $W_o$, then bias $b_o$ is added. Finally, the sigmoid is applied to the sum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output $h_t$ is then the product of $o_t$ and $\\tanh(C_t)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "LSTM units work because they maintain a cell state that controls the gradient flow. The gates open and close, learning weights such that errors are appropriately scaled, trapped, and released. This facilitates a constant error flow that prevents gradients from exploding or vanishing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we outline a possible implemenation of the LSTM class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Parameter\n",
    "\n",
    "class LSTM(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        mean = torch.tensor(0.0)\n",
    "        std = torch.tensor(1.0)\n",
    "\n",
    "        # Initialize forget gate weights\n",
    "        self.wf = Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.bf = Parameter(torch.tensor(0.0), requires_grad=True)\n",
    "\n",
    "        # Initialize input gate weights\n",
    "        self.wi = Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.bi = Parameter(torch.tensor(0.0), requires_grad=True)\n",
    "\n",
    "        # Initialize candidate gate weights\n",
    "        self.wc = Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.bc = Parameter(torch.tensor(0.0), requires_grad=True)\n",
    "\n",
    "        # Initialize output gate weights\n",
    "        self.wo = Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.bo = Parameter(torch.tensor(0.0), requires_grad=True)\n",
    "\n",
    "    def lstm_unit(self, input, cell_state, short_memory):\n",
    "        \"\"\"Does the calculations for the LSTM unit.\"\"\"\n",
    "        \n",
    "        # Calculating forget and input gate values\n",
    "        ft = torch.sigmoid((self.wf * input) + (self.wf * short_memory) + self.bf)\n",
    "        it = torch.sigmoid((self.wi * input) + (self.wi * short_memory) + self.bi)\n",
    "        candidates = torch.tanh((self.wc * input) + (self.wc * short_memory) + self.bc)\n",
    "\n",
    "        # Update the cell state\n",
    "        updated_cell_state = (ft * cell_state) + (it * candidates)\n",
    "\n",
    "        # Output gate\n",
    "        ot = torch.sigmoid((self.wo * input) + (self.wo * short_memory) + self.bo)\n",
    "        ht = torch.tanh(cell_state) * ot\n",
    "\n",
    "        return updated_cell_state, ht\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"A forward pass. Here were assume input is an array/list.\n",
    "           Depending on the needs, the inputs may need to be\n",
    "           handled differently.\"\"\"\n",
    "        \n",
    "        cell_state = 0\n",
    "        short_memory = 0\n",
    "\n",
    "        for item in input:\n",
    "            cell_state, short_memory = self.lstm_unit(item, cell_state, short_memory)\n",
    "            \n",
    "        return short_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the constructor, we initialize all the weights and biases. In this particular implementation, we randomly set the weights based on a normal distribution around mean 0 and standard deviation 1. The biases are initialized to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a helper function `lstm_unit` to perform the calculations that occur in the LSTM unit. Values are calculated based on the formulas above and the function returns the updated cell state and short term memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, in the `forward` method, we iterate through the input and perform the LSTM calculations, returning the updated short term memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Generation\n",
    "\n",
    "We explore music generation using techniques similar to the charRNN model. The structure of our code is as follows:\n",
    "\n",
    "- **`music_preprocessing.py`**: Converts `.mid` and `.krn` files into data trainable by LSTM.\n",
    "- **`get_data.py`**: Transforms the training data into `torch.tensors`.\n",
    "- **`buildLSTM.py`**: Defines and trains the neural network.\n",
    "- **`generate_music.py`**: Generates music using the trained model.\n",
    "\n",
    "### Data Pre-processing Challenge\n",
    "\n",
    "One significant challenge in music generation is data pre-processing. Music is not in a readily usable form, requiring extensive pre-processing to convert it into trainable data.\n",
    "\n",
    "**Step One**: Our dataset is in `.erk` format, and we use the `music21` library to convert music notation into numerical data. This process is handled in `music_preprocessing.py`. Here is a brief overview of its functionality:\n",
    "\n",
    "- **Transposition**: Since our training dataset contains music in various keys, we first transpose the music to either C major or A minor.\n",
    "- **Pitch Conversion**: After transposition, we convert the music to their respective pitches in string format. For more details, see the function `music_encoder`. Running this file generates a new folder `__data_preprocessing__` containing digital music converted to pitches.\n",
    "\n",
    "After this step, our preprocessed music would look like this:\n",
    "\n",
    "`62 _ _ _ _ _ _ _ r _ _ _ 64 _ 67 _ 65 _ _ _ 64 _ _ _`\n",
    "\n",
    "where the numbers are pitch values, `_` denotes the temporal duration of the note/rest, and `r` denotes rest. To see its actual power, please run the line below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music_preprocessing import preprocess_midi_files\n",
    "preprocess_midi_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step Two**: Transform the string of pitches into a dataset for training, handled in `get_data.py`.\n",
    "\n",
    "- **String to Tokens**: We tokenize the string and store a dictionary of tokens. The string is then tokenized and one-hot encoded. Running this file generates a new folder `music_to_integer_dictionary` containing a dictionary of tokens for pitches.\n",
    "\n",
    "**Step Three**: Implement LSTM for music generation, with a simple structure. Note that the input size and output size are equal to the vocabulary size in our training set. Below is our structure:\n",
    "\n",
    "- **Neural Network Structure**: We pass the data through a one-layer LSTM model followed by a linear layer of size `(hidden_size * SEQUENCE_LENGTH, output_size)` and then apply the activation function. Some research articles show that stacked LSTMs would produce the best effect for music generation, but we consider a simple layer is sufficient for our purposes here and easier for training. You can read more [here](https://arxiv.org/abs/2203.12105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn  \n",
    "SEQUENCE_LENGTH = 64\n",
    "class LSTMModel(nn.Module): \n",
    "    def __init__(self, input_size, output_size, hidden_size, \n",
    "                 number_of_layers, \n",
    "                 dropout_prob):  \n",
    "        super().__init__()\n",
    "        self.lstms = nn.LSTM(input_size, hidden_size, dropout = dropout_prob, batch_first = True, num_layers = number_of_layers)  \n",
    "        self.dense = nn.Linear(hidden_size * SEQUENCE_LENGTH, output_size)\n",
    "        self.number_of_layers = number_of_layers \n",
    "        self.hidden_size = hidden_size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of our neural network is extremely simple. We first pass the data into lstms and then a linear layer of size `(hidden_size * SEQUENCE_LENGTH, output_size)` and then perform the activation function. \n",
    "\n",
    "**Step Four**: After completing the training, we can then the evaluation step and generate music based on our seed. To give a simple example, the seed\n",
    "\n",
    "`seed = \"65 _ _ _ 65 _ 69\"`\n",
    "\n",
    "will provide music like the following: \n",
    "![music_sample](./img/music_screenshot.jpg) \n",
    "\n",
    "You can change the seed of your choice in the file `generate_music.py` and execute the file to generate your own music!\n",
    "\n",
    "In the music generation process, we have implemented a temperature sampling which allows our ouput to be more random and thus generates creative music. This is basically redefining a new softmax function: \n",
    "$$\n",
    "\\text{softmax}(x_i) = \\frac{e^{x_i / T}}{\\sum^{n}_{j = 1}e^{x_j / T}}\n",
    "$$\n",
    "where $T$ denotes the hyperparameter for temperature value. As $T \\rightarrow \\infty$, we see that the process becomes more random; as $T \\rightarrow 0$, we see the process becomes more deterministic and thus repetitive. To avoid repetitive generation, we are interested in a sufficiently high value of temperature. You can read more about it [here](https://towardsdatascience.com/how-to-sample-from-language-models-682bceb97277).\n",
    "\n",
    "\n",
    "The implementation is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch.nn.functional as F \n",
    "\n",
    "def sample_with_temperature(self, probabilites, temperature):\n",
    "    '''\n",
    "    Samples an index from a probability array using temperature sampling.\n",
    "        \n",
    "    Parameters:\n",
    "        probabilities (torch.Tensor): Tensor of probabilities for each possible output.\n",
    "        temperature (float): Controls the randomness of predictions by scaling the logits before applying softmax.\n",
    "        \n",
    "    Returns:\n",
    "        index (int): The selected index based on the sampling.\n",
    "        '''\n",
    "    probabilites = probabilites.squeeze() \n",
    "    predictions = torch.log(probabilites) / temperature\n",
    "    probabilites = F.softmax(predictions, dim = -1)\n",
    "    choices = range(len(probabilites))\n",
    "    probabilites = probabilites.detach().numpy()\n",
    "    index = np.random.choice(choices, p = probabilites)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Improvements and Considerations\n",
    "\n",
    "The project is by no means complete, and many further improvements are possible. Here are some suggestions:\n",
    "\n",
    "- Polyphonic Music\n",
    "\n",
    "  - **Current Limitation**: Our music generation model currently only processes monophonic music.\n",
    "  - **Future Exploration**: An interesting question would be how to incorporate polyphonic music into our model such as multi-layer voiced music, multiple instruments, and complex chords. Can we add more instruments to create chamber music? \n",
    "  - **Complexity Goal**: Can we generate music with the complexity as shown below?\n",
    "  ![beethoven](./img/beethoven.jpg)\n",
    "\n",
    "- Hyperparameter Tuning\n",
    "\n",
    "  - **Current State**: We have provided some hyperparameters in the file `buildLSTM.py`.\n",
    "  - **Future Work**: Try to find the best hyperparameters to generate beautiful music.\n",
    "  - **Performance Improvement**: Furthermore, explore ways to improve the training speed. \n",
    "\n",
    "- Sampling Technique\n",
    "\n",
    "  - **Current Issue**: A drawback in `sample_with_temperature` is that it can potentially disrupt the overall structure of the musical flow.\n",
    "  - **Future Enhancement**: Is there a better sampling technique available that could make our music more coherent?\n",
    "\n",
    "- Score Representation\n",
    "\n",
    "  - **Current Limitation**: The current implementation for converting music is still a bit hard to read.\n",
    "  - **Future Improvement**: Explore ways to make the score more visually appealing, such as dividing it into treble clef and bass clef."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
